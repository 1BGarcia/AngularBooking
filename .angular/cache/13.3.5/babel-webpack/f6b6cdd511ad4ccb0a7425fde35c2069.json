{"ast":null,"code":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n*/\n\"use strict\";\n\nvar _asyncToGenerator = require(\"E:\\\\M7ProyectoAngular\\\\node_modules\\\\@babel\\\\runtime\\\\helpers\\\\asyncToGenerator.js\").default;\n\nconst {\n  constants\n} = require(\"buffer\");\n\nconst {\n  pipeline\n} = require(\"stream\");\n\nconst {\n  createBrotliCompress,\n  createBrotliDecompress,\n  createGzip,\n  createGunzip,\n  constants: zConstants\n} = require(\"zlib\");\n\nconst createHash = require(\"../util/createHash\");\n\nconst {\n  dirname,\n  join,\n  mkdirp\n} = require(\"../util/fs\");\n\nconst memoize = require(\"../util/memoize\");\n\nconst SerializerMiddleware = require(\"./SerializerMiddleware\");\n/** @typedef {typeof import(\"../util/Hash\")} Hash */\n\n/** @typedef {import(\"../util/fs\").IntermediateFileSystem} IntermediateFileSystem */\n\n/** @typedef {import(\"./types\").BufferSerializableType} BufferSerializableType */\n\n/*\nFormat:\n\nFile -> Header Section*\n\nVersion -> u32\nAmountOfSections -> u32\nSectionSize -> i32 (if less than zero represents lazy value)\n\nHeader -> Version AmountOfSections SectionSize*\n\nBuffer -> n bytes\nSection -> Buffer\n\n*/\n// \"wpc\" + 1 in little-endian\n\n\nconst VERSION = 0x01637077;\nconst WRITE_LIMIT_TOTAL = 0x7fff0000;\nconst WRITE_LIMIT_CHUNK = 511 * 1024 * 1024;\n/**\n * @param {Buffer[]} buffers buffers\n * @param {string | Hash} hashFunction hash function to use\n * @returns {string} hash\n */\n\nconst hashForName = (buffers, hashFunction) => {\n  const hash = createHash(hashFunction);\n\n  for (const buf of buffers) hash.update(buf);\n\n  return (\n    /** @type {string} */\n    hash.digest(\"hex\")\n  );\n};\n\nconst COMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst DECOMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst writeUInt64LE = Buffer.prototype.writeBigUInt64LE ? (buf, value, offset) => {\n  buf.writeBigUInt64LE(BigInt(value), offset);\n} : (buf, value, offset) => {\n  const low = value % 0x100000000;\n  const high = (value - low) / 0x100000000;\n  buf.writeUInt32LE(low, offset);\n  buf.writeUInt32LE(high, offset + 4);\n};\nconst readUInt64LE = Buffer.prototype.readBigUInt64LE ? (buf, offset) => {\n  return Number(buf.readBigUInt64LE(offset));\n} : (buf, offset) => {\n  const low = buf.readUInt32LE(offset);\n  const high = buf.readUInt32LE(offset + 4);\n  return high * 0x100000000 + low;\n};\n/**\n * @typedef {Object} SerializeResult\n * @property {string | false} name\n * @property {number} size\n * @property {Promise=} backgroundJob\n */\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {BufferSerializableType[] | Promise<BufferSerializableType[]>} data data to be serialized\n * @param {string | boolean} name file base name\n * @param {function(string | false, Buffer[], number): Promise<void>} writeFile writes a file\n * @param {string | Hash} hashFunction hash function to use\n * @returns {Promise<SerializeResult>} resulting file pointer and promise\n */\n\nconst serialize = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(function* (middleware, data, name, writeFile, hashFunction = \"md4\") {\n    /** @type {(Buffer[] | Buffer | SerializeResult | Promise<SerializeResult>)[]} */\n    const processedData = [];\n    /** @type {WeakMap<SerializeResult, function(): any | Promise<any>>} */\n\n    const resultToLazy = new WeakMap();\n    /** @type {Buffer[]} */\n\n    let lastBuffers = undefined;\n\n    for (const item of yield data) {\n      if (typeof item === \"function\") {\n        if (!SerializerMiddleware.isLazy(item)) throw new Error(\"Unexpected function\");\n\n        if (!SerializerMiddleware.isLazy(item, middleware)) {\n          throw new Error(\"Unexpected lazy value with non-this target (can't pass through lazy values)\");\n        }\n\n        lastBuffers = undefined;\n        const serializedInfo = SerializerMiddleware.getLazySerializedValue(item);\n\n        if (serializedInfo) {\n          if (typeof serializedInfo === \"function\") {\n            throw new Error(\"Unexpected lazy value with non-this target (can't pass through lazy values)\");\n          } else {\n            processedData.push(serializedInfo);\n          }\n        } else {\n          const content = item();\n\n          if (content) {\n            const options = SerializerMiddleware.getLazyOptions(item);\n            processedData.push(serialize(middleware, content, options && options.name || true, writeFile, hashFunction).then(result => {\n              /** @type {any} */\n              item.options.size = result.size;\n              resultToLazy.set(result, item);\n              return result;\n            }));\n          } else {\n            throw new Error(\"Unexpected falsy value returned by lazy value function\");\n          }\n        }\n      } else if (item) {\n        if (lastBuffers) {\n          lastBuffers.push(item);\n        } else {\n          lastBuffers = [item];\n          processedData.push(lastBuffers);\n        }\n      } else {\n        throw new Error(\"Unexpected falsy value in items array\");\n      }\n    }\n    /** @type {Promise<any>[]} */\n\n\n    const backgroundJobs = [];\n    const resolvedData = (yield Promise.all(\n    /** @type {Promise<Buffer[] | Buffer | SerializeResult>[]} */\n    processedData)).map(item => {\n      if (Array.isArray(item) || Buffer.isBuffer(item)) return item;\n      backgroundJobs.push(item.backgroundJob); // create pointer buffer from size and name\n\n      const name =\n      /** @type {string} */\n      item.name;\n      const nameBuffer = Buffer.from(name);\n      const buf = Buffer.allocUnsafe(8 + nameBuffer.length);\n      writeUInt64LE(buf, item.size, 0);\n      nameBuffer.copy(buf, 8, 0);\n      const lazy = resultToLazy.get(item);\n      SerializerMiddleware.setLazySerializedValue(lazy, buf);\n      return buf;\n    });\n    const lengths = [];\n\n    for (const item of resolvedData) {\n      if (Array.isArray(item)) {\n        let l = 0;\n\n        for (const b of item) l += b.length;\n\n        while (l > 0x7fffffff) {\n          lengths.push(0x7fffffff);\n          l -= 0x7fffffff;\n        }\n\n        lengths.push(l);\n      } else if (item) {\n        lengths.push(-item.length);\n      } else {\n        throw new Error(\"Unexpected falsy value in resolved data \" + item);\n      }\n    }\n\n    const header = Buffer.allocUnsafe(8 + lengths.length * 4);\n    header.writeUInt32LE(VERSION, 0);\n    header.writeUInt32LE(lengths.length, 4);\n\n    for (let i = 0; i < lengths.length; i++) {\n      header.writeInt32LE(lengths[i], 8 + i * 4);\n    }\n\n    const buf = [header];\n\n    for (const item of resolvedData) {\n      if (Array.isArray(item)) {\n        for (const b of item) buf.push(b);\n      } else if (item) {\n        buf.push(item);\n      }\n    }\n\n    if (name === true) {\n      name = hashForName(buf, hashFunction);\n    }\n\n    let size = 0;\n\n    for (const b of buf) size += b.length;\n\n    backgroundJobs.push(writeFile(name, buf, size));\n    return {\n      size,\n      name,\n      backgroundJob: backgroundJobs.length === 1 ? backgroundJobs[0] : Promise.all(backgroundJobs)\n    };\n  });\n\n  return function serialize(_x, _x2, _x3, _x4) {\n    return _ref.apply(this, arguments);\n  };\n}();\n/**\n * @param {FileMiddleware} middleware this\n * @param {string | false} name filename\n * @param {function(string | false): Promise<Buffer[]>} readFile read content of a file\n * @returns {Promise<BufferSerializableType[]>} deserialized data\n */\n\n\nconst deserialize = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator(function* (middleware, name, readFile) {\n    const contents = yield readFile(name);\n    if (contents.length === 0) throw new Error(\"Empty file \" + name);\n    let contentsIndex = 0;\n    let contentItem = contents[0];\n    let contentItemLength = contentItem.length;\n    let contentPosition = 0;\n    if (contentItemLength === 0) throw new Error(\"Empty file \" + name);\n\n    const nextContent = () => {\n      contentsIndex++;\n      contentItem = contents[contentsIndex];\n      contentItemLength = contentItem.length;\n      contentPosition = 0;\n    };\n\n    const ensureData = n => {\n      if (contentPosition === contentItemLength) {\n        nextContent();\n      }\n\n      while (contentItemLength - contentPosition < n) {\n        const remaining = contentItem.slice(contentPosition);\n        let lengthFromNext = n - remaining.length;\n        const buffers = [remaining];\n\n        for (let i = contentsIndex + 1; i < contents.length; i++) {\n          const l = contents[i].length;\n\n          if (l > lengthFromNext) {\n            buffers.push(contents[i].slice(0, lengthFromNext));\n            contents[i] = contents[i].slice(lengthFromNext);\n            lengthFromNext = 0;\n            break;\n          } else {\n            buffers.push(contents[i]);\n            contentsIndex = i;\n            lengthFromNext -= l;\n          }\n        }\n\n        if (lengthFromNext > 0) throw new Error(\"Unexpected end of data\");\n        contentItem = Buffer.concat(buffers, n);\n        contentItemLength = n;\n        contentPosition = 0;\n      }\n    };\n\n    const readUInt32LE = () => {\n      ensureData(4);\n      const value = contentItem.readUInt32LE(contentPosition);\n      contentPosition += 4;\n      return value;\n    };\n\n    const readInt32LE = () => {\n      ensureData(4);\n      const value = contentItem.readInt32LE(contentPosition);\n      contentPosition += 4;\n      return value;\n    };\n\n    const readSlice = l => {\n      ensureData(l);\n\n      if (contentPosition === 0 && contentItemLength === l) {\n        const result = contentItem;\n\n        if (contentsIndex + 1 < contents.length) {\n          nextContent();\n        } else {\n          contentPosition = l;\n        }\n\n        return result;\n      }\n\n      const result = contentItem.slice(contentPosition, contentPosition + l);\n      contentPosition += l; // we clone the buffer here to allow the original content to be garbage collected\n\n      return l * 2 < contentItem.buffer.byteLength ? Buffer.from(result) : result;\n    };\n\n    const version = readUInt32LE();\n\n    if (version !== VERSION) {\n      throw new Error(\"Invalid file version\");\n    }\n\n    const sectionCount = readUInt32LE();\n    const lengths = [];\n    let lastLengthPositive = false;\n\n    for (let i = 0; i < sectionCount; i++) {\n      const value = readInt32LE();\n      const valuePositive = value >= 0;\n\n      if (lastLengthPositive && valuePositive) {\n        lengths[lengths.length - 1] += value;\n      } else {\n        lengths.push(value);\n        lastLengthPositive = valuePositive;\n      }\n    }\n\n    const result = [];\n\n    for (let length of lengths) {\n      if (length < 0) {\n        const slice = readSlice(-length);\n        const size = Number(readUInt64LE(slice, 0));\n        const nameBuffer = slice.slice(8);\n        const name = nameBuffer.toString();\n        result.push(SerializerMiddleware.createLazy(memoize(() => deserialize(middleware, name, readFile)), middleware, {\n          name,\n          size\n        }, slice));\n      } else {\n        if (contentPosition === contentItemLength) {\n          nextContent();\n        } else if (contentPosition !== 0) {\n          if (length <= contentItemLength - contentPosition) {\n            result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset + contentPosition, length));\n            contentPosition += length;\n            length = 0;\n          } else {\n            const l = contentItemLength - contentPosition;\n            result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset + contentPosition, l));\n            length -= l;\n            contentPosition = contentItemLength;\n          }\n        } else {\n          if (length >= contentItemLength) {\n            result.push(contentItem);\n            length -= contentItemLength;\n            contentPosition = contentItemLength;\n          } else {\n            result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset, length));\n            contentPosition += length;\n            length = 0;\n          }\n        }\n\n        while (length > 0) {\n          nextContent();\n\n          if (length >= contentItemLength) {\n            result.push(contentItem);\n            length -= contentItemLength;\n            contentPosition = contentItemLength;\n          } else {\n            result.push(Buffer.from(contentItem.buffer, contentItem.byteOffset, length));\n            contentPosition += length;\n            length = 0;\n          }\n        }\n      }\n    }\n\n    return result;\n  });\n\n  return function deserialize(_x5, _x6, _x7) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n/**\n * @typedef {BufferSerializableType[]} DeserializedType\n * @typedef {true} SerializedType\n * @extends {SerializerMiddleware<DeserializedType, SerializedType>}\n */\n\n\nclass FileMiddleware extends SerializerMiddleware {\n  /**\n   * @param {IntermediateFileSystem} fs filesystem\n   * @param {string | Hash} hashFunction hash function to use\n   */\n  constructor(fs, hashFunction = \"md4\") {\n    super();\n    this.fs = fs;\n    this._hashFunction = hashFunction;\n  }\n  /**\n   * @param {DeserializedType} data data\n   * @param {Object} context context object\n   * @returns {SerializedType|Promise<SerializedType>} serialized data\n   */\n\n\n  serialize(data, context) {\n    var _this = this;\n\n    const {\n      filename,\n      extension = \"\"\n    } = context;\n    return new Promise((resolve, reject) => {\n      mkdirp(this.fs, dirname(this.fs, filename), err => {\n        if (err) return reject(err); // It's important that we don't touch existing files during serialization\n        // because serialize may read existing files (when deserializing)\n\n        const allWrittenFiles = new Set();\n\n        const writeFile = /*#__PURE__*/function () {\n          var _ref3 = _asyncToGenerator(function* (name, content, size) {\n            const file = name ? join(_this.fs, filename, `../${name}${extension}`) : filename;\n            yield new Promise((resolve, reject) => {\n              let stream = _this.fs.createWriteStream(file + \"_\");\n\n              let compression;\n\n              if (file.endsWith(\".gz\")) {\n                compression = createGzip({\n                  chunkSize: COMPRESSION_CHUNK_SIZE,\n                  level: zConstants.Z_BEST_SPEED\n                });\n              } else if (file.endsWith(\".br\")) {\n                compression = createBrotliCompress({\n                  chunkSize: COMPRESSION_CHUNK_SIZE,\n                  params: {\n                    [zConstants.BROTLI_PARAM_MODE]: zConstants.BROTLI_MODE_TEXT,\n                    [zConstants.BROTLI_PARAM_QUALITY]: 2,\n                    [zConstants.BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING]: true,\n                    [zConstants.BROTLI_PARAM_SIZE_HINT]: size\n                  }\n                });\n              }\n\n              if (compression) {\n                pipeline(compression, stream, reject);\n                stream = compression;\n                stream.on(\"finish\", () => resolve());\n              } else {\n                stream.on(\"error\", err => reject(err));\n                stream.on(\"finish\", () => resolve());\n              } // split into chunks for WRITE_LIMIT_CHUNK size\n\n\n              const chunks = [];\n\n              for (const b of content) {\n                if (b.length < WRITE_LIMIT_CHUNK) {\n                  chunks.push(b);\n                } else {\n                  for (let i = 0; i < b.length; i += WRITE_LIMIT_CHUNK) {\n                    chunks.push(b.slice(i, i + WRITE_LIMIT_CHUNK));\n                  }\n                }\n              }\n\n              const len = chunks.length;\n              let i = 0;\n\n              const batchWrite = err => {\n                // will be handled in \"on\" error handler\n                if (err) return;\n\n                if (i === len) {\n                  stream.end();\n                  return;\n                } // queue up a batch of chunks up to the write limit\n                // end is exclusive\n\n\n                let end = i;\n                let sum = chunks[end++].length;\n\n                while (end < len) {\n                  sum += chunks[end].length;\n                  if (sum > WRITE_LIMIT_TOTAL) break;\n                  end++;\n                }\n\n                while (i < end - 1) {\n                  stream.write(chunks[i++]);\n                }\n\n                stream.write(chunks[i++], batchWrite);\n              };\n\n              batchWrite();\n            });\n            if (name) allWrittenFiles.add(file);\n          });\n\n          return function writeFile(_x8, _x9, _x10) {\n            return _ref3.apply(this, arguments);\n          };\n        }();\n\n        resolve(serialize(this, data, false, writeFile, this._hashFunction).then( /*#__PURE__*/function () {\n          var _ref4 = _asyncToGenerator(function* ({\n            backgroundJob\n          }) {\n            yield backgroundJob; // Rename the index file to disallow access during inconsistent file state\n\n            yield new Promise(resolve => _this.fs.rename(filename, filename + \".old\", err => {\n              resolve();\n            })); // update all written files\n\n            yield Promise.all(Array.from(allWrittenFiles, file => new Promise((resolve, reject) => {\n              _this.fs.rename(file + \"_\", file, err => {\n                if (err) return reject(err);\n                resolve();\n              });\n            }))); // As final step automatically update the index file to have a consistent pack again\n\n            yield new Promise(resolve => {\n              _this.fs.rename(filename + \"_\", filename, err => {\n                if (err) return reject(err);\n                resolve();\n              });\n            });\n            return (\n              /** @type {true} */\n              true\n            );\n          });\n\n          return function (_x11) {\n            return _ref4.apply(this, arguments);\n          };\n        }()));\n      });\n    });\n  }\n  /**\n   * @param {SerializedType} data data\n   * @param {Object} context context object\n   * @returns {DeserializedType|Promise<DeserializedType>} deserialized data\n   */\n\n\n  deserialize(data, context) {\n    const {\n      filename,\n      extension = \"\"\n    } = context;\n\n    const readFile = name => new Promise((resolve, reject) => {\n      const file = name ? join(this.fs, filename, `../${name}${extension}`) : filename;\n      this.fs.stat(file, (err, stats) => {\n        if (err) {\n          reject(err);\n          return;\n        }\n\n        let remaining =\n        /** @type {number} */\n        stats.size;\n        let currentBuffer;\n        let currentBufferUsed;\n        const buf = [];\n        let decompression;\n\n        if (file.endsWith(\".gz\")) {\n          decompression = createGunzip({\n            chunkSize: DECOMPRESSION_CHUNK_SIZE\n          });\n        } else if (file.endsWith(\".br\")) {\n          decompression = createBrotliDecompress({\n            chunkSize: DECOMPRESSION_CHUNK_SIZE\n          });\n        }\n\n        if (decompression) {\n          let newResolve, newReject;\n          resolve(Promise.all([new Promise((rs, rj) => {\n            newResolve = rs;\n            newReject = rj;\n          }), new Promise((resolve, reject) => {\n            decompression.on(\"data\", chunk => buf.push(chunk));\n            decompression.on(\"end\", () => resolve());\n            decompression.on(\"error\", err => reject(err));\n          })]).then(() => buf));\n          resolve = newResolve;\n          reject = newReject;\n        }\n\n        this.fs.open(file, \"r\", (err, fd) => {\n          if (err) {\n            reject(err);\n            return;\n          }\n\n          const read = () => {\n            if (currentBuffer === undefined) {\n              currentBuffer = Buffer.allocUnsafeSlow(Math.min(constants.MAX_LENGTH, remaining, decompression ? DECOMPRESSION_CHUNK_SIZE : Infinity));\n              currentBufferUsed = 0;\n            }\n\n            let readBuffer = currentBuffer;\n            let readOffset = currentBufferUsed;\n            let readLength = currentBuffer.length - currentBufferUsed; // values passed to fs.read must be valid int32 values\n\n            if (readOffset > 0x7fffffff) {\n              readBuffer = currentBuffer.slice(readOffset);\n              readOffset = 0;\n            }\n\n            if (readLength > 0x7fffffff) {\n              readLength = 0x7fffffff;\n            }\n\n            this.fs.read(fd, readBuffer, readOffset, readLength, null, (err, bytesRead) => {\n              if (err) {\n                this.fs.close(fd, () => {\n                  reject(err);\n                });\n                return;\n              }\n\n              currentBufferUsed += bytesRead;\n              remaining -= bytesRead;\n\n              if (currentBufferUsed === currentBuffer.length) {\n                if (decompression) {\n                  decompression.write(currentBuffer);\n                } else {\n                  buf.push(currentBuffer);\n                }\n\n                currentBuffer = undefined;\n\n                if (remaining === 0) {\n                  if (decompression) {\n                    decompression.end();\n                  }\n\n                  this.fs.close(fd, err => {\n                    if (err) {\n                      reject(err);\n                      return;\n                    }\n\n                    resolve(buf);\n                  });\n                  return;\n                }\n              }\n\n              read();\n            });\n          };\n\n          read();\n        });\n      });\n    });\n\n    return deserialize(this, false, readFile);\n  }\n\n}\n\nmodule.exports = FileMiddleware;","map":{"version":3,"sources":["E:/M7ProyectoAngular/node_modules/webpack/lib/serialization/FileMiddleware.js"],"names":["constants","require","pipeline","createBrotliCompress","createBrotliDecompress","createGzip","createGunzip","zConstants","createHash","dirname","join","mkdirp","memoize","SerializerMiddleware","VERSION","WRITE_LIMIT_TOTAL","WRITE_LIMIT_CHUNK","hashForName","buffers","hashFunction","hash","buf","update","digest","COMPRESSION_CHUNK_SIZE","DECOMPRESSION_CHUNK_SIZE","writeUInt64LE","Buffer","prototype","writeBigUInt64LE","value","offset","BigInt","low","high","writeUInt32LE","readUInt64LE","readBigUInt64LE","Number","readUInt32LE","serialize","middleware","data","name","writeFile","processedData","resultToLazy","WeakMap","lastBuffers","undefined","item","isLazy","Error","serializedInfo","getLazySerializedValue","push","content","options","getLazyOptions","then","result","size","set","backgroundJobs","resolvedData","Promise","all","map","Array","isArray","isBuffer","backgroundJob","nameBuffer","from","allocUnsafe","length","copy","lazy","get","setLazySerializedValue","lengths","l","b","header","i","writeInt32LE","deserialize","readFile","contents","contentsIndex","contentItem","contentItemLength","contentPosition","nextContent","ensureData","n","remaining","slice","lengthFromNext","concat","readInt32LE","readSlice","buffer","byteLength","version","sectionCount","lastLengthPositive","valuePositive","toString","createLazy","byteOffset","FileMiddleware","constructor","fs","_hashFunction","context","filename","extension","resolve","reject","err","allWrittenFiles","Set","file","stream","createWriteStream","compression","endsWith","chunkSize","level","Z_BEST_SPEED","params","BROTLI_PARAM_MODE","BROTLI_MODE_TEXT","BROTLI_PARAM_QUALITY","BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING","BROTLI_PARAM_SIZE_HINT","on","chunks","len","batchWrite","end","sum","write","add","rename","stat","stats","currentBuffer","currentBufferUsed","decompression","newResolve","newReject","rs","rj","chunk","open","fd","read","allocUnsafeSlow","Math","min","MAX_LENGTH","Infinity","readBuffer","readOffset","readLength","bytesRead","close","module","exports"],"mappings":"AAAA;AACA;AACA;AAEA;;;;AAEA,MAAM;AAAEA,EAAAA;AAAF,IAAgBC,OAAO,CAAC,QAAD,CAA7B;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAAeD,OAAO,CAAC,QAAD,CAA5B;;AACA,MAAM;AACLE,EAAAA,oBADK;AAELC,EAAAA,sBAFK;AAGLC,EAAAA,UAHK;AAILC,EAAAA,YAJK;AAKLN,EAAAA,SAAS,EAAEO;AALN,IAMFN,OAAO,CAAC,MAAD,CANX;;AAOA,MAAMO,UAAU,GAAGP,OAAO,CAAC,oBAAD,CAA1B;;AACA,MAAM;AAAEQ,EAAAA,OAAF;AAAWC,EAAAA,IAAX;AAAiBC,EAAAA;AAAjB,IAA4BV,OAAO,CAAC,YAAD,CAAzC;;AACA,MAAMW,OAAO,GAAGX,OAAO,CAAC,iBAAD,CAAvB;;AACA,MAAMY,oBAAoB,GAAGZ,OAAO,CAAC,wBAAD,CAApC;AAEA;;AACA;;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AACA,MAAMa,OAAO,GAAG,UAAhB;AACA,MAAMC,iBAAiB,GAAG,UAA1B;AACA,MAAMC,iBAAiB,GAAG,MAAM,IAAN,GAAa,IAAvC;AAEA;AACA;AACA;AACA;AACA;;AACA,MAAMC,WAAW,GAAG,CAACC,OAAD,EAAUC,YAAV,KAA2B;AAC9C,QAAMC,IAAI,GAAGZ,UAAU,CAACW,YAAD,CAAvB;;AACA,OAAK,MAAME,GAAX,IAAkBH,OAAlB,EAA2BE,IAAI,CAACE,MAAL,CAAYD,GAAZ;;AAC3B;AAAO;AAAuBD,IAAAA,IAAI,CAACG,MAAL,CAAY,KAAZ;AAA9B;AACA,CAJD;;AAMA,MAAMC,sBAAsB,GAAG,MAAM,IAAN,GAAa,IAA5C;AACA,MAAMC,wBAAwB,GAAG,MAAM,IAAN,GAAa,IAA9C;AAEA,MAAMC,aAAa,GAAGC,MAAM,CAACC,SAAP,CAAiBC,gBAAjB,GACnB,CAACR,GAAD,EAAMS,KAAN,EAAaC,MAAb,KAAwB;AACxBV,EAAAA,GAAG,CAACQ,gBAAJ,CAAqBG,MAAM,CAACF,KAAD,CAA3B,EAAoCC,MAApC;AACC,CAHkB,GAInB,CAACV,GAAD,EAAMS,KAAN,EAAaC,MAAb,KAAwB;AACxB,QAAME,GAAG,GAAGH,KAAK,GAAG,WAApB;AACA,QAAMI,IAAI,GAAG,CAACJ,KAAK,GAAGG,GAAT,IAAgB,WAA7B;AACAZ,EAAAA,GAAG,CAACc,aAAJ,CAAkBF,GAAlB,EAAuBF,MAAvB;AACAV,EAAAA,GAAG,CAACc,aAAJ,CAAkBD,IAAlB,EAAwBH,MAAM,GAAG,CAAjC;AACC,CATJ;AAWA,MAAMK,YAAY,GAAGT,MAAM,CAACC,SAAP,CAAiBS,eAAjB,GAClB,CAAChB,GAAD,EAAMU,MAAN,KAAiB;AACjB,SAAOO,MAAM,CAACjB,GAAG,CAACgB,eAAJ,CAAoBN,MAApB,CAAD,CAAb;AACC,CAHiB,GAIlB,CAACV,GAAD,EAAMU,MAAN,KAAiB;AACjB,QAAME,GAAG,GAAGZ,GAAG,CAACkB,YAAJ,CAAiBR,MAAjB,CAAZ;AACA,QAAMG,IAAI,GAAGb,GAAG,CAACkB,YAAJ,CAAiBR,MAAM,GAAG,CAA1B,CAAb;AACA,SAAOG,IAAI,GAAG,WAAP,GAAqBD,GAA5B;AACC,CARJ;AAUA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAMO,SAAS;AAAA,+BAAG,WACjBC,UADiB,EAEjBC,IAFiB,EAGjBC,IAHiB,EAIjBC,SAJiB,EAKjBzB,YAAY,GAAG,KALE,EAMb;AACJ;AACA,UAAM0B,aAAa,GAAG,EAAtB;AACA;;AACA,UAAMC,YAAY,GAAG,IAAIC,OAAJ,EAArB;AACA;;AACA,QAAIC,WAAW,GAAGC,SAAlB;;AACA,SAAK,MAAMC,IAAX,UAAyBR,IAAzB,EAA+B;AAC9B,UAAI,OAAOQ,IAAP,KAAgB,UAApB,EAAgC;AAC/B,YAAI,CAACrC,oBAAoB,CAACsC,MAArB,CAA4BD,IAA5B,CAAL,EACC,MAAM,IAAIE,KAAJ,CAAU,qBAAV,CAAN;;AACD,YAAI,CAACvC,oBAAoB,CAACsC,MAArB,CAA4BD,IAA5B,EAAkCT,UAAlC,CAAL,EAAoD;AACnD,gBAAM,IAAIW,KAAJ,CACL,6EADK,CAAN;AAGA;;AACDJ,QAAAA,WAAW,GAAGC,SAAd;AACA,cAAMI,cAAc,GAAGxC,oBAAoB,CAACyC,sBAArB,CAA4CJ,IAA5C,CAAvB;;AACA,YAAIG,cAAJ,EAAoB;AACnB,cAAI,OAAOA,cAAP,KAA0B,UAA9B,EAA0C;AACzC,kBAAM,IAAID,KAAJ,CACL,6EADK,CAAN;AAGA,WAJD,MAIO;AACNP,YAAAA,aAAa,CAACU,IAAd,CAAmBF,cAAnB;AACA;AACD,SARD,MAQO;AACN,gBAAMG,OAAO,GAAGN,IAAI,EAApB;;AACA,cAAIM,OAAJ,EAAa;AACZ,kBAAMC,OAAO,GAAG5C,oBAAoB,CAAC6C,cAArB,CAAoCR,IAApC,CAAhB;AACAL,YAAAA,aAAa,CAACU,IAAd,CACCf,SAAS,CACRC,UADQ,EAERe,OAFQ,EAGPC,OAAO,IAAIA,OAAO,CAACd,IAApB,IAA6B,IAHrB,EAIRC,SAJQ,EAKRzB,YALQ,CAAT,CAMEwC,IANF,CAMOC,MAAM,IAAI;AAChB;AAAoBV,cAAAA,IAAD,CAAOO,OAAP,CAAeI,IAAf,GAAsBD,MAAM,CAACC,IAA7B;AACnBf,cAAAA,YAAY,CAACgB,GAAb,CAAiBF,MAAjB,EAAyBV,IAAzB;AACA,qBAAOU,MAAP;AACA,aAVD,CADD;AAaA,WAfD,MAeO;AACN,kBAAM,IAAIR,KAAJ,CACL,wDADK,CAAN;AAGA;AACD;AACD,OAzCD,MAyCO,IAAIF,IAAJ,EAAU;AAChB,YAAIF,WAAJ,EAAiB;AAChBA,UAAAA,WAAW,CAACO,IAAZ,CAAiBL,IAAjB;AACA,SAFD,MAEO;AACNF,UAAAA,WAAW,GAAG,CAACE,IAAD,CAAd;AACAL,UAAAA,aAAa,CAACU,IAAd,CAAmBP,WAAnB;AACA;AACD,OAPM,MAOA;AACN,cAAM,IAAII,KAAJ,CAAU,uCAAV,CAAN;AACA;AACD;AACD;;;AACA,UAAMW,cAAc,GAAG,EAAvB;AACA,UAAMC,YAAY,GAAG,OACdC,OAAO,CAACC,GAAR;AACL;AACCrB,IAAAA,aAFI,CADc,EAMnBsB,GANmB,CAMfjB,IAAI,IAAI;AACb,UAAIkB,KAAK,CAACC,OAAN,CAAcnB,IAAd,KAAuBvB,MAAM,CAAC2C,QAAP,CAAgBpB,IAAhB,CAA3B,EAAkD,OAAOA,IAAP;AAElDa,MAAAA,cAAc,CAACR,IAAf,CAAoBL,IAAI,CAACqB,aAAzB,EAHa,CAIb;;AACA,YAAM5B,IAAI;AAAG;AAAuBO,MAAAA,IAAI,CAACP,IAAzC;AACA,YAAM6B,UAAU,GAAG7C,MAAM,CAAC8C,IAAP,CAAY9B,IAAZ,CAAnB;AACA,YAAMtB,GAAG,GAAGM,MAAM,CAAC+C,WAAP,CAAmB,IAAIF,UAAU,CAACG,MAAlC,CAAZ;AACAjD,MAAAA,aAAa,CAACL,GAAD,EAAM6B,IAAI,CAACW,IAAX,EAAiB,CAAjB,CAAb;AACAW,MAAAA,UAAU,CAACI,IAAX,CAAgBvD,GAAhB,EAAqB,CAArB,EAAwB,CAAxB;AACA,YAAMwD,IAAI,GAAG/B,YAAY,CAACgC,GAAb,CAAiB5B,IAAjB,CAAb;AACArC,MAAAA,oBAAoB,CAACkE,sBAArB,CAA4CF,IAA5C,EAAkDxD,GAAlD;AACA,aAAOA,GAAP;AACA,KAnBoB,CAArB;AAoBA,UAAM2D,OAAO,GAAG,EAAhB;;AACA,SAAK,MAAM9B,IAAX,IAAmBc,YAAnB,EAAiC;AAChC,UAAII,KAAK,CAACC,OAAN,CAAcnB,IAAd,CAAJ,EAAyB;AACxB,YAAI+B,CAAC,GAAG,CAAR;;AACA,aAAK,MAAMC,CAAX,IAAgBhC,IAAhB,EAAsB+B,CAAC,IAAIC,CAAC,CAACP,MAAP;;AACtB,eAAOM,CAAC,GAAG,UAAX,EAAuB;AACtBD,UAAAA,OAAO,CAACzB,IAAR,CAAa,UAAb;AACA0B,UAAAA,CAAC,IAAI,UAAL;AACA;;AACDD,QAAAA,OAAO,CAACzB,IAAR,CAAa0B,CAAb;AACA,OARD,MAQO,IAAI/B,IAAJ,EAAU;AAChB8B,QAAAA,OAAO,CAACzB,IAAR,CAAa,CAACL,IAAI,CAACyB,MAAnB;AACA,OAFM,MAEA;AACN,cAAM,IAAIvB,KAAJ,CAAU,6CAA6CF,IAAvD,CAAN;AACA;AACD;;AACD,UAAMiC,MAAM,GAAGxD,MAAM,CAAC+C,WAAP,CAAmB,IAAIM,OAAO,CAACL,MAAR,GAAiB,CAAxC,CAAf;AACAQ,IAAAA,MAAM,CAAChD,aAAP,CAAqBrB,OAArB,EAA8B,CAA9B;AACAqE,IAAAA,MAAM,CAAChD,aAAP,CAAqB6C,OAAO,CAACL,MAA7B,EAAqC,CAArC;;AACA,SAAK,IAAIS,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,OAAO,CAACL,MAA5B,EAAoCS,CAAC,EAArC,EAAyC;AACxCD,MAAAA,MAAM,CAACE,YAAP,CAAoBL,OAAO,CAACI,CAAD,CAA3B,EAAgC,IAAIA,CAAC,GAAG,CAAxC;AACA;;AACD,UAAM/D,GAAG,GAAG,CAAC8D,MAAD,CAAZ;;AACA,SAAK,MAAMjC,IAAX,IAAmBc,YAAnB,EAAiC;AAChC,UAAII,KAAK,CAACC,OAAN,CAAcnB,IAAd,CAAJ,EAAyB;AACxB,aAAK,MAAMgC,CAAX,IAAgBhC,IAAhB,EAAsB7B,GAAG,CAACkC,IAAJ,CAAS2B,CAAT;AACtB,OAFD,MAEO,IAAIhC,IAAJ,EAAU;AAChB7B,QAAAA,GAAG,CAACkC,IAAJ,CAASL,IAAT;AACA;AACD;;AACD,QAAIP,IAAI,KAAK,IAAb,EAAmB;AAClBA,MAAAA,IAAI,GAAG1B,WAAW,CAACI,GAAD,EAAMF,YAAN,CAAlB;AACA;;AACD,QAAI0C,IAAI,GAAG,CAAX;;AACA,SAAK,MAAMqB,CAAX,IAAgB7D,GAAhB,EAAqBwC,IAAI,IAAIqB,CAAC,CAACP,MAAV;;AACrBZ,IAAAA,cAAc,CAACR,IAAf,CAAoBX,SAAS,CAACD,IAAD,EAAOtB,GAAP,EAAYwC,IAAZ,CAA7B;AACA,WAAO;AACNA,MAAAA,IADM;AAENlB,MAAAA,IAFM;AAGN4B,MAAAA,aAAa,EACZR,cAAc,CAACY,MAAf,KAA0B,CAA1B,GACGZ,cAAc,CAAC,CAAD,CADjB,GAEGE,OAAO,CAACC,GAAR,CAAYH,cAAZ;AANE,KAAP;AAQA,GApIc;;AAAA,kBAATvB,SAAS;AAAA;AAAA;AAAA,GAAf;AAsIA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAM8C,WAAW;AAAA,gCAAG,WAAO7C,UAAP,EAAmBE,IAAnB,EAAyB4C,QAAzB,EAAsC;AACzD,UAAMC,QAAQ,SAASD,QAAQ,CAAC5C,IAAD,CAA/B;AACA,QAAI6C,QAAQ,CAACb,MAAT,KAAoB,CAAxB,EAA2B,MAAM,IAAIvB,KAAJ,CAAU,gBAAgBT,IAA1B,CAAN;AAC3B,QAAI8C,aAAa,GAAG,CAApB;AACA,QAAIC,WAAW,GAAGF,QAAQ,CAAC,CAAD,CAA1B;AACA,QAAIG,iBAAiB,GAAGD,WAAW,CAACf,MAApC;AACA,QAAIiB,eAAe,GAAG,CAAtB;AACA,QAAID,iBAAiB,KAAK,CAA1B,EAA6B,MAAM,IAAIvC,KAAJ,CAAU,gBAAgBT,IAA1B,CAAN;;AAC7B,UAAMkD,WAAW,GAAG,MAAM;AACzBJ,MAAAA,aAAa;AACbC,MAAAA,WAAW,GAAGF,QAAQ,CAACC,aAAD,CAAtB;AACAE,MAAAA,iBAAiB,GAAGD,WAAW,CAACf,MAAhC;AACAiB,MAAAA,eAAe,GAAG,CAAlB;AACA,KALD;;AAMA,UAAME,UAAU,GAAGC,CAAC,IAAI;AACvB,UAAIH,eAAe,KAAKD,iBAAxB,EAA2C;AAC1CE,QAAAA,WAAW;AACX;;AACD,aAAOF,iBAAiB,GAAGC,eAApB,GAAsCG,CAA7C,EAAgD;AAC/C,cAAMC,SAAS,GAAGN,WAAW,CAACO,KAAZ,CAAkBL,eAAlB,CAAlB;AACA,YAAIM,cAAc,GAAGH,CAAC,GAAGC,SAAS,CAACrB,MAAnC;AACA,cAAMzD,OAAO,GAAG,CAAC8E,SAAD,CAAhB;;AACA,aAAK,IAAIZ,CAAC,GAAGK,aAAa,GAAG,CAA7B,EAAgCL,CAAC,GAAGI,QAAQ,CAACb,MAA7C,EAAqDS,CAAC,EAAtD,EAA0D;AACzD,gBAAMH,CAAC,GAAGO,QAAQ,CAACJ,CAAD,CAAR,CAAYT,MAAtB;;AACA,cAAIM,CAAC,GAAGiB,cAAR,EAAwB;AACvBhF,YAAAA,OAAO,CAACqC,IAAR,CAAaiC,QAAQ,CAACJ,CAAD,CAAR,CAAYa,KAAZ,CAAkB,CAAlB,EAAqBC,cAArB,CAAb;AACAV,YAAAA,QAAQ,CAACJ,CAAD,CAAR,GAAcI,QAAQ,CAACJ,CAAD,CAAR,CAAYa,KAAZ,CAAkBC,cAAlB,CAAd;AACAA,YAAAA,cAAc,GAAG,CAAjB;AACA;AACA,WALD,MAKO;AACNhF,YAAAA,OAAO,CAACqC,IAAR,CAAaiC,QAAQ,CAACJ,CAAD,CAArB;AACAK,YAAAA,aAAa,GAAGL,CAAhB;AACAc,YAAAA,cAAc,IAAIjB,CAAlB;AACA;AACD;;AACD,YAAIiB,cAAc,GAAG,CAArB,EAAwB,MAAM,IAAI9C,KAAJ,CAAU,wBAAV,CAAN;AACxBsC,QAAAA,WAAW,GAAG/D,MAAM,CAACwE,MAAP,CAAcjF,OAAd,EAAuB6E,CAAvB,CAAd;AACAJ,QAAAA,iBAAiB,GAAGI,CAApB;AACAH,QAAAA,eAAe,GAAG,CAAlB;AACA;AACD,KA1BD;;AA2BA,UAAMrD,YAAY,GAAG,MAAM;AAC1BuD,MAAAA,UAAU,CAAC,CAAD,CAAV;AACA,YAAMhE,KAAK,GAAG4D,WAAW,CAACnD,YAAZ,CAAyBqD,eAAzB,CAAd;AACAA,MAAAA,eAAe,IAAI,CAAnB;AACA,aAAO9D,KAAP;AACA,KALD;;AAMA,UAAMsE,WAAW,GAAG,MAAM;AACzBN,MAAAA,UAAU,CAAC,CAAD,CAAV;AACA,YAAMhE,KAAK,GAAG4D,WAAW,CAACU,WAAZ,CAAwBR,eAAxB,CAAd;AACAA,MAAAA,eAAe,IAAI,CAAnB;AACA,aAAO9D,KAAP;AACA,KALD;;AAMA,UAAMuE,SAAS,GAAGpB,CAAC,IAAI;AACtBa,MAAAA,UAAU,CAACb,CAAD,CAAV;;AACA,UAAIW,eAAe,KAAK,CAApB,IAAyBD,iBAAiB,KAAKV,CAAnD,EAAsD;AACrD,cAAMrB,MAAM,GAAG8B,WAAf;;AACA,YAAID,aAAa,GAAG,CAAhB,GAAoBD,QAAQ,CAACb,MAAjC,EAAyC;AACxCkB,UAAAA,WAAW;AACX,SAFD,MAEO;AACND,UAAAA,eAAe,GAAGX,CAAlB;AACA;;AACD,eAAOrB,MAAP;AACA;;AACD,YAAMA,MAAM,GAAG8B,WAAW,CAACO,KAAZ,CAAkBL,eAAlB,EAAmCA,eAAe,GAAGX,CAArD,CAAf;AACAW,MAAAA,eAAe,IAAIX,CAAnB,CAZsB,CAatB;;AACA,aAAOA,CAAC,GAAG,CAAJ,GAAQS,WAAW,CAACY,MAAZ,CAAmBC,UAA3B,GAAwC5E,MAAM,CAAC8C,IAAP,CAAYb,MAAZ,CAAxC,GAA8DA,MAArE;AACA,KAfD;;AAgBA,UAAM4C,OAAO,GAAGjE,YAAY,EAA5B;;AACA,QAAIiE,OAAO,KAAK1F,OAAhB,EAAyB;AACxB,YAAM,IAAIsC,KAAJ,CAAU,sBAAV,CAAN;AACA;;AACD,UAAMqD,YAAY,GAAGlE,YAAY,EAAjC;AACA,UAAMyC,OAAO,GAAG,EAAhB;AACA,QAAI0B,kBAAkB,GAAG,KAAzB;;AACA,SAAK,IAAItB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGqB,YAApB,EAAkCrB,CAAC,EAAnC,EAAuC;AACtC,YAAMtD,KAAK,GAAGsE,WAAW,EAAzB;AACA,YAAMO,aAAa,GAAG7E,KAAK,IAAI,CAA/B;;AACA,UAAI4E,kBAAkB,IAAIC,aAA1B,EAAyC;AACxC3B,QAAAA,OAAO,CAACA,OAAO,CAACL,MAAR,GAAiB,CAAlB,CAAP,IAA+B7C,KAA/B;AACA,OAFD,MAEO;AACNkD,QAAAA,OAAO,CAACzB,IAAR,CAAazB,KAAb;AACA4E,QAAAA,kBAAkB,GAAGC,aAArB;AACA;AACD;;AACD,UAAM/C,MAAM,GAAG,EAAf;;AACA,SAAK,IAAIe,MAAT,IAAmBK,OAAnB,EAA4B;AAC3B,UAAIL,MAAM,GAAG,CAAb,EAAgB;AACf,cAAMsB,KAAK,GAAGI,SAAS,CAAC,CAAC1B,MAAF,CAAvB;AACA,cAAMd,IAAI,GAAGvB,MAAM,CAACF,YAAY,CAAC6D,KAAD,EAAQ,CAAR,CAAb,CAAnB;AACA,cAAMzB,UAAU,GAAGyB,KAAK,CAACA,KAAN,CAAY,CAAZ,CAAnB;AACA,cAAMtD,IAAI,GAAG6B,UAAU,CAACoC,QAAX,EAAb;AACAhD,QAAAA,MAAM,CAACL,IAAP,CACC1C,oBAAoB,CAACgG,UAArB,CACCjG,OAAO,CAAC,MAAM0E,WAAW,CAAC7C,UAAD,EAAaE,IAAb,EAAmB4C,QAAnB,CAAlB,CADR,EAEC9C,UAFD,EAGC;AACCE,UAAAA,IADD;AAECkB,UAAAA;AAFD,SAHD,EAOCoC,KAPD,CADD;AAWA,OAhBD,MAgBO;AACN,YAAIL,eAAe,KAAKD,iBAAxB,EAA2C;AAC1CE,UAAAA,WAAW;AACX,SAFD,MAEO,IAAID,eAAe,KAAK,CAAxB,EAA2B;AACjC,cAAIjB,MAAM,IAAIgB,iBAAiB,GAAGC,eAAlC,EAAmD;AAClDhC,YAAAA,MAAM,CAACL,IAAP,CACC5B,MAAM,CAAC8C,IAAP,CACCiB,WAAW,CAACY,MADb,EAECZ,WAAW,CAACoB,UAAZ,GAAyBlB,eAF1B,EAGCjB,MAHD,CADD;AAOAiB,YAAAA,eAAe,IAAIjB,MAAnB;AACAA,YAAAA,MAAM,GAAG,CAAT;AACA,WAVD,MAUO;AACN,kBAAMM,CAAC,GAAGU,iBAAiB,GAAGC,eAA9B;AACAhC,YAAAA,MAAM,CAACL,IAAP,CACC5B,MAAM,CAAC8C,IAAP,CACCiB,WAAW,CAACY,MADb,EAECZ,WAAW,CAACoB,UAAZ,GAAyBlB,eAF1B,EAGCX,CAHD,CADD;AAOAN,YAAAA,MAAM,IAAIM,CAAV;AACAW,YAAAA,eAAe,GAAGD,iBAAlB;AACA;AACD,SAvBM,MAuBA;AACN,cAAIhB,MAAM,IAAIgB,iBAAd,EAAiC;AAChC/B,YAAAA,MAAM,CAACL,IAAP,CAAYmC,WAAZ;AACAf,YAAAA,MAAM,IAAIgB,iBAAV;AACAC,YAAAA,eAAe,GAAGD,iBAAlB;AACA,WAJD,MAIO;AACN/B,YAAAA,MAAM,CAACL,IAAP,CACC5B,MAAM,CAAC8C,IAAP,CAAYiB,WAAW,CAACY,MAAxB,EAAgCZ,WAAW,CAACoB,UAA5C,EAAwDnC,MAAxD,CADD;AAGAiB,YAAAA,eAAe,IAAIjB,MAAnB;AACAA,YAAAA,MAAM,GAAG,CAAT;AACA;AACD;;AACD,eAAOA,MAAM,GAAG,CAAhB,EAAmB;AAClBkB,UAAAA,WAAW;;AACX,cAAIlB,MAAM,IAAIgB,iBAAd,EAAiC;AAChC/B,YAAAA,MAAM,CAACL,IAAP,CAAYmC,WAAZ;AACAf,YAAAA,MAAM,IAAIgB,iBAAV;AACAC,YAAAA,eAAe,GAAGD,iBAAlB;AACA,WAJD,MAIO;AACN/B,YAAAA,MAAM,CAACL,IAAP,CACC5B,MAAM,CAAC8C,IAAP,CAAYiB,WAAW,CAACY,MAAxB,EAAgCZ,WAAW,CAACoB,UAA5C,EAAwDnC,MAAxD,CADD;AAGAiB,YAAAA,eAAe,IAAIjB,MAAnB;AACAA,YAAAA,MAAM,GAAG,CAAT;AACA;AACD;AACD;AACD;;AACD,WAAOf,MAAP;AACA,GAhKgB;;AAAA,kBAAX0B,WAAW;AAAA;AAAA;AAAA,GAAjB;AAkKA;AACA;AACA;AACA;AACA;;;AACA,MAAMyB,cAAN,SAA6BlG,oBAA7B,CAAkD;AACjD;AACD;AACA;AACA;AACCmG,EAAAA,WAAW,CAACC,EAAD,EAAK9F,YAAY,GAAG,KAApB,EAA2B;AACrC;AACA,SAAK8F,EAAL,GAAUA,EAAV;AACA,SAAKC,aAAL,GAAqB/F,YAArB;AACA;AACD;AACD;AACA;AACA;AACA;;;AACCqB,EAAAA,SAAS,CAACE,IAAD,EAAOyE,OAAP,EAAgB;AAAA;;AACxB,UAAM;AAAEC,MAAAA,QAAF;AAAYC,MAAAA,SAAS,GAAG;AAAxB,QAA+BF,OAArC;AACA,WAAO,IAAIlD,OAAJ,CAAY,CAACqD,OAAD,EAAUC,MAAV,KAAqB;AACvC5G,MAAAA,MAAM,CAAC,KAAKsG,EAAN,EAAUxG,OAAO,CAAC,KAAKwG,EAAN,EAAUG,QAAV,CAAjB,EAAsCI,GAAG,IAAI;AAClD,YAAIA,GAAJ,EAAS,OAAOD,MAAM,CAACC,GAAD,CAAb,CADyC,CAGlD;AACA;;AACA,cAAMC,eAAe,GAAG,IAAIC,GAAJ,EAAxB;;AACA,cAAM9E,SAAS;AAAA,wCAAG,WAAOD,IAAP,EAAaa,OAAb,EAAsBK,IAAtB,EAA+B;AAChD,kBAAM8D,IAAI,GAAGhF,IAAI,GACdjC,IAAI,CAAC,KAAI,CAACuG,EAAN,EAAUG,QAAV,EAAqB,MAAKzE,IAAK,GAAE0E,SAAU,EAA3C,CADU,GAEdD,QAFH;AAGA,kBAAM,IAAInD,OAAJ,CAAY,CAACqD,OAAD,EAAUC,MAAV,KAAqB;AACtC,kBAAIK,MAAM,GAAG,KAAI,CAACX,EAAL,CAAQY,iBAAR,CAA0BF,IAAI,GAAG,GAAjC,CAAb;;AACA,kBAAIG,WAAJ;;AACA,kBAAIH,IAAI,CAACI,QAAL,CAAc,KAAd,CAAJ,EAA0B;AACzBD,gBAAAA,WAAW,GAAGzH,UAAU,CAAC;AACxB2H,kBAAAA,SAAS,EAAExG,sBADa;AAExByG,kBAAAA,KAAK,EAAE1H,UAAU,CAAC2H;AAFM,iBAAD,CAAxB;AAIA,eALD,MAKO,IAAIP,IAAI,CAACI,QAAL,CAAc,KAAd,CAAJ,EAA0B;AAChCD,gBAAAA,WAAW,GAAG3H,oBAAoB,CAAC;AAClC6H,kBAAAA,SAAS,EAAExG,sBADuB;AAElC2G,kBAAAA,MAAM,EAAE;AACP,qBAAC5H,UAAU,CAAC6H,iBAAZ,GAAgC7H,UAAU,CAAC8H,gBADpC;AAEP,qBAAC9H,UAAU,CAAC+H,oBAAZ,GAAmC,CAF5B;AAGP,qBAAC/H,UAAU,CAACgI,6CAAZ,GAA4D,IAHrD;AAIP,qBAAChI,UAAU,CAACiI,sBAAZ,GAAqC3E;AAJ9B;AAF0B,iBAAD,CAAlC;AASA;;AACD,kBAAIiE,WAAJ,EAAiB;AAChB5H,gBAAAA,QAAQ,CAAC4H,WAAD,EAAcF,MAAd,EAAsBL,MAAtB,CAAR;AACAK,gBAAAA,MAAM,GAAGE,WAAT;AACAF,gBAAAA,MAAM,CAACa,EAAP,CAAU,QAAV,EAAoB,MAAMnB,OAAO,EAAjC;AACA,eAJD,MAIO;AACNM,gBAAAA,MAAM,CAACa,EAAP,CAAU,OAAV,EAAmBjB,GAAG,IAAID,MAAM,CAACC,GAAD,CAAhC;AACAI,gBAAAA,MAAM,CAACa,EAAP,CAAU,QAAV,EAAoB,MAAMnB,OAAO,EAAjC;AACA,eA1BqC,CA2BtC;;;AACA,oBAAMoB,MAAM,GAAG,EAAf;;AACA,mBAAK,MAAMxD,CAAX,IAAgB1B,OAAhB,EAAyB;AACxB,oBAAI0B,CAAC,CAACP,MAAF,GAAW3D,iBAAf,EAAkC;AACjC0H,kBAAAA,MAAM,CAACnF,IAAP,CAAY2B,CAAZ;AACA,iBAFD,MAEO;AACN,uBAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,CAAC,CAACP,MAAtB,EAA8BS,CAAC,IAAIpE,iBAAnC,EAAsD;AACrD0H,oBAAAA,MAAM,CAACnF,IAAP,CAAY2B,CAAC,CAACe,KAAF,CAAQb,CAAR,EAAWA,CAAC,GAAGpE,iBAAf,CAAZ;AACA;AACD;AACD;;AAED,oBAAM2H,GAAG,GAAGD,MAAM,CAAC/D,MAAnB;AACA,kBAAIS,CAAC,GAAG,CAAR;;AACA,oBAAMwD,UAAU,GAAGpB,GAAG,IAAI;AACzB;AACA,oBAAIA,GAAJ,EAAS;;AAET,oBAAIpC,CAAC,KAAKuD,GAAV,EAAe;AACdf,kBAAAA,MAAM,CAACiB,GAAP;AACA;AACA,iBAPwB,CASzB;AACA;;;AACA,oBAAIA,GAAG,GAAGzD,CAAV;AACA,oBAAI0D,GAAG,GAAGJ,MAAM,CAACG,GAAG,EAAJ,CAAN,CAAclE,MAAxB;;AACA,uBAAOkE,GAAG,GAAGF,GAAb,EAAkB;AACjBG,kBAAAA,GAAG,IAAIJ,MAAM,CAACG,GAAD,CAAN,CAAYlE,MAAnB;AACA,sBAAImE,GAAG,GAAG/H,iBAAV,EAA6B;AAC7B8H,kBAAAA,GAAG;AACH;;AACD,uBAAOzD,CAAC,GAAGyD,GAAG,GAAG,CAAjB,EAAoB;AACnBjB,kBAAAA,MAAM,CAACmB,KAAP,CAAaL,MAAM,CAACtD,CAAC,EAAF,CAAnB;AACA;;AACDwC,gBAAAA,MAAM,CAACmB,KAAP,CAAaL,MAAM,CAACtD,CAAC,EAAF,CAAnB,EAA0BwD,UAA1B;AACA,eAtBD;;AAuBAA,cAAAA,UAAU;AACV,aAjEK,CAAN;AAkEA,gBAAIjG,IAAJ,EAAU8E,eAAe,CAACuB,GAAhB,CAAoBrB,IAApB;AACV,WAvEc;;AAAA,0BAAT/E,SAAS;AAAA;AAAA;AAAA,WAAf;;AAyEA0E,QAAAA,OAAO,CACN9E,SAAS,CAAC,IAAD,EAAOE,IAAP,EAAa,KAAb,EAAoBE,SAApB,EAA+B,KAAKsE,aAApC,CAAT,CAA4DvD,IAA5D;AAAA,wCACC,WAAO;AAAEY,YAAAA;AAAF,WAAP,EAA6B;AAC5B,kBAAMA,aAAN,CAD4B,CAG5B;;AACA,kBAAM,IAAIN,OAAJ,CAAYqD,OAAO,IACxB,KAAI,CAACL,EAAL,CAAQgC,MAAR,CAAe7B,QAAf,EAAyBA,QAAQ,GAAG,MAApC,EAA4CI,GAAG,IAAI;AAClDF,cAAAA,OAAO;AACP,aAFD,CADK,CAAN,CAJ4B,CAU5B;;AACA,kBAAMrD,OAAO,CAACC,GAAR,CACLE,KAAK,CAACK,IAAN,CACCgD,eADD,EAECE,IAAI,IACH,IAAI1D,OAAJ,CAAY,CAACqD,OAAD,EAAUC,MAAV,KAAqB;AAChC,cAAA,KAAI,CAACN,EAAL,CAAQgC,MAAR,CAAetB,IAAI,GAAG,GAAtB,EAA2BA,IAA3B,EAAiCH,GAAG,IAAI;AACvC,oBAAIA,GAAJ,EAAS,OAAOD,MAAM,CAACC,GAAD,CAAb;AACTF,gBAAAA,OAAO;AACP,eAHD;AAIA,aALD,CAHF,CADK,CAAN,CAX4B,CAwB5B;;AACA,kBAAM,IAAIrD,OAAJ,CAAYqD,OAAO,IAAI;AAC5B,cAAA,KAAI,CAACL,EAAL,CAAQgC,MAAR,CAAe7B,QAAQ,GAAG,GAA1B,EAA+BA,QAA/B,EAAyCI,GAAG,IAAI;AAC/C,oBAAIA,GAAJ,EAAS,OAAOD,MAAM,CAACC,GAAD,CAAb;AACTF,gBAAAA,OAAO;AACP,eAHD;AAIA,aALK,CAAN;AAMA;AAAO;AAAqB;AAA5B;AACA,WAjCF;;AAAA;AAAA;AAAA;AAAA,YADM,CAAP;AAqCA,OApHK,CAAN;AAqHA,KAtHM,CAAP;AAuHA;AAED;AACD;AACA;AACA;AACA;;;AACChC,EAAAA,WAAW,CAAC5C,IAAD,EAAOyE,OAAP,EAAgB;AAC1B,UAAM;AAAEC,MAAAA,QAAF;AAAYC,MAAAA,SAAS,GAAG;AAAxB,QAA+BF,OAArC;;AACA,UAAM5B,QAAQ,GAAG5C,IAAI,IACpB,IAAIsB,OAAJ,CAAY,CAACqD,OAAD,EAAUC,MAAV,KAAqB;AAChC,YAAMI,IAAI,GAAGhF,IAAI,GACdjC,IAAI,CAAC,KAAKuG,EAAN,EAAUG,QAAV,EAAqB,MAAKzE,IAAK,GAAE0E,SAAU,EAA3C,CADU,GAEdD,QAFH;AAGA,WAAKH,EAAL,CAAQiC,IAAR,CAAavB,IAAb,EAAmB,CAACH,GAAD,EAAM2B,KAAN,KAAgB;AAClC,YAAI3B,GAAJ,EAAS;AACRD,UAAAA,MAAM,CAACC,GAAD,CAAN;AACA;AACA;;AACD,YAAIxB,SAAS;AAAG;AAAuBmD,QAAAA,KAAK,CAACtF,IAA7C;AACA,YAAIuF,aAAJ;AACA,YAAIC,iBAAJ;AACA,cAAMhI,GAAG,GAAG,EAAZ;AACA,YAAIiI,aAAJ;;AACA,YAAI3B,IAAI,CAACI,QAAL,CAAc,KAAd,CAAJ,EAA0B;AACzBuB,UAAAA,aAAa,GAAGhJ,YAAY,CAAC;AAC5B0H,YAAAA,SAAS,EAAEvG;AADiB,WAAD,CAA5B;AAGA,SAJD,MAIO,IAAIkG,IAAI,CAACI,QAAL,CAAc,KAAd,CAAJ,EAA0B;AAChCuB,UAAAA,aAAa,GAAGlJ,sBAAsB,CAAC;AACtC4H,YAAAA,SAAS,EAAEvG;AAD2B,WAAD,CAAtC;AAGA;;AACD,YAAI6H,aAAJ,EAAmB;AAClB,cAAIC,UAAJ,EAAgBC,SAAhB;AACAlC,UAAAA,OAAO,CACNrD,OAAO,CAACC,GAAR,CAAY,CACX,IAAID,OAAJ,CAAY,CAACwF,EAAD,EAAKC,EAAL,KAAY;AACvBH,YAAAA,UAAU,GAAGE,EAAb;AACAD,YAAAA,SAAS,GAAGE,EAAZ;AACA,WAHD,CADW,EAKX,IAAIzF,OAAJ,CAAY,CAACqD,OAAD,EAAUC,MAAV,KAAqB;AAChC+B,YAAAA,aAAa,CAACb,EAAd,CAAiB,MAAjB,EAAyBkB,KAAK,IAAItI,GAAG,CAACkC,IAAJ,CAASoG,KAAT,CAAlC;AACAL,YAAAA,aAAa,CAACb,EAAd,CAAiB,KAAjB,EAAwB,MAAMnB,OAAO,EAArC;AACAgC,YAAAA,aAAa,CAACb,EAAd,CAAiB,OAAjB,EAA0BjB,GAAG,IAAID,MAAM,CAACC,GAAD,CAAvC;AACA,WAJD,CALW,CAAZ,EAUG7D,IAVH,CAUQ,MAAMtC,GAVd,CADM,CAAP;AAaAiG,UAAAA,OAAO,GAAGiC,UAAV;AACAhC,UAAAA,MAAM,GAAGiC,SAAT;AACA;;AACD,aAAKvC,EAAL,CAAQ2C,IAAR,CAAajC,IAAb,EAAmB,GAAnB,EAAwB,CAACH,GAAD,EAAMqC,EAAN,KAAa;AACpC,cAAIrC,GAAJ,EAAS;AACRD,YAAAA,MAAM,CAACC,GAAD,CAAN;AACA;AACA;;AACD,gBAAMsC,IAAI,GAAG,MAAM;AAClB,gBAAIV,aAAa,KAAKnG,SAAtB,EAAiC;AAChCmG,cAAAA,aAAa,GAAGzH,MAAM,CAACoI,eAAP,CACfC,IAAI,CAACC,GAAL,CACCjK,SAAS,CAACkK,UADX,EAEClE,SAFD,EAGCsD,aAAa,GAAG7H,wBAAH,GAA8B0I,QAH5C,CADe,CAAhB;AAOAd,cAAAA,iBAAiB,GAAG,CAApB;AACA;;AACD,gBAAIe,UAAU,GAAGhB,aAAjB;AACA,gBAAIiB,UAAU,GAAGhB,iBAAjB;AACA,gBAAIiB,UAAU,GAAGlB,aAAa,CAACzE,MAAd,GAAuB0E,iBAAxC,CAbkB,CAclB;;AACA,gBAAIgB,UAAU,GAAG,UAAjB,EAA6B;AAC5BD,cAAAA,UAAU,GAAGhB,aAAa,CAACnD,KAAd,CAAoBoE,UAApB,CAAb;AACAA,cAAAA,UAAU,GAAG,CAAb;AACA;;AACD,gBAAIC,UAAU,GAAG,UAAjB,EAA6B;AAC5BA,cAAAA,UAAU,GAAG,UAAb;AACA;;AACD,iBAAKrD,EAAL,CAAQ6C,IAAR,CACCD,EADD,EAECO,UAFD,EAGCC,UAHD,EAICC,UAJD,EAKC,IALD,EAMC,CAAC9C,GAAD,EAAM+C,SAAN,KAAoB;AACnB,kBAAI/C,GAAJ,EAAS;AACR,qBAAKP,EAAL,CAAQuD,KAAR,CAAcX,EAAd,EAAkB,MAAM;AACvBtC,kBAAAA,MAAM,CAACC,GAAD,CAAN;AACA,iBAFD;AAGA;AACA;;AACD6B,cAAAA,iBAAiB,IAAIkB,SAArB;AACAvE,cAAAA,SAAS,IAAIuE,SAAb;;AACA,kBAAIlB,iBAAiB,KAAKD,aAAa,CAACzE,MAAxC,EAAgD;AAC/C,oBAAI2E,aAAJ,EAAmB;AAClBA,kBAAAA,aAAa,CAACP,KAAd,CAAoBK,aAApB;AACA,iBAFD,MAEO;AACN/H,kBAAAA,GAAG,CAACkC,IAAJ,CAAS6F,aAAT;AACA;;AACDA,gBAAAA,aAAa,GAAGnG,SAAhB;;AACA,oBAAI+C,SAAS,KAAK,CAAlB,EAAqB;AACpB,sBAAIsD,aAAJ,EAAmB;AAClBA,oBAAAA,aAAa,CAACT,GAAd;AACA;;AACD,uBAAK5B,EAAL,CAAQuD,KAAR,CAAcX,EAAd,EAAkBrC,GAAG,IAAI;AACxB,wBAAIA,GAAJ,EAAS;AACRD,sBAAAA,MAAM,CAACC,GAAD,CAAN;AACA;AACA;;AACDF,oBAAAA,OAAO,CAACjG,GAAD,CAAP;AACA,mBAND;AAOA;AACA;AACD;;AACDyI,cAAAA,IAAI;AACJ,aArCF;AAuCA,WA7DD;;AA8DAA,UAAAA,IAAI;AACJ,SApED;AAqEA,OA1GD;AA2GA,KA/GD,CADD;;AAiHA,WAAOxE,WAAW,CAAC,IAAD,EAAO,KAAP,EAAcC,QAAd,CAAlB;AACA;;AAnQgD;;AAsQlDkF,MAAM,CAACC,OAAP,GAAiB3D,cAAjB","sourcesContent":["/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n*/\n\n\"use strict\";\n\nconst { constants } = require(\"buffer\");\nconst { pipeline } = require(\"stream\");\nconst {\n\tcreateBrotliCompress,\n\tcreateBrotliDecompress,\n\tcreateGzip,\n\tcreateGunzip,\n\tconstants: zConstants\n} = require(\"zlib\");\nconst createHash = require(\"../util/createHash\");\nconst { dirname, join, mkdirp } = require(\"../util/fs\");\nconst memoize = require(\"../util/memoize\");\nconst SerializerMiddleware = require(\"./SerializerMiddleware\");\n\n/** @typedef {typeof import(\"../util/Hash\")} Hash */\n/** @typedef {import(\"../util/fs\").IntermediateFileSystem} IntermediateFileSystem */\n/** @typedef {import(\"./types\").BufferSerializableType} BufferSerializableType */\n\n/*\nFormat:\n\nFile -> Header Section*\n\nVersion -> u32\nAmountOfSections -> u32\nSectionSize -> i32 (if less than zero represents lazy value)\n\nHeader -> Version AmountOfSections SectionSize*\n\nBuffer -> n bytes\nSection -> Buffer\n\n*/\n\n// \"wpc\" + 1 in little-endian\nconst VERSION = 0x01637077;\nconst WRITE_LIMIT_TOTAL = 0x7fff0000;\nconst WRITE_LIMIT_CHUNK = 511 * 1024 * 1024;\n\n/**\n * @param {Buffer[]} buffers buffers\n * @param {string | Hash} hashFunction hash function to use\n * @returns {string} hash\n */\nconst hashForName = (buffers, hashFunction) => {\n\tconst hash = createHash(hashFunction);\n\tfor (const buf of buffers) hash.update(buf);\n\treturn /** @type {string} */ (hash.digest(\"hex\"));\n};\n\nconst COMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\nconst DECOMPRESSION_CHUNK_SIZE = 100 * 1024 * 1024;\n\nconst writeUInt64LE = Buffer.prototype.writeBigUInt64LE\n\t? (buf, value, offset) => {\n\t\t\tbuf.writeBigUInt64LE(BigInt(value), offset);\n\t  }\n\t: (buf, value, offset) => {\n\t\t\tconst low = value % 0x100000000;\n\t\t\tconst high = (value - low) / 0x100000000;\n\t\t\tbuf.writeUInt32LE(low, offset);\n\t\t\tbuf.writeUInt32LE(high, offset + 4);\n\t  };\n\nconst readUInt64LE = Buffer.prototype.readBigUInt64LE\n\t? (buf, offset) => {\n\t\t\treturn Number(buf.readBigUInt64LE(offset));\n\t  }\n\t: (buf, offset) => {\n\t\t\tconst low = buf.readUInt32LE(offset);\n\t\t\tconst high = buf.readUInt32LE(offset + 4);\n\t\t\treturn high * 0x100000000 + low;\n\t  };\n\n/**\n * @typedef {Object} SerializeResult\n * @property {string | false} name\n * @property {number} size\n * @property {Promise=} backgroundJob\n */\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {BufferSerializableType[] | Promise<BufferSerializableType[]>} data data to be serialized\n * @param {string | boolean} name file base name\n * @param {function(string | false, Buffer[], number): Promise<void>} writeFile writes a file\n * @param {string | Hash} hashFunction hash function to use\n * @returns {Promise<SerializeResult>} resulting file pointer and promise\n */\nconst serialize = async (\n\tmiddleware,\n\tdata,\n\tname,\n\twriteFile,\n\thashFunction = \"md4\"\n) => {\n\t/** @type {(Buffer[] | Buffer | SerializeResult | Promise<SerializeResult>)[]} */\n\tconst processedData = [];\n\t/** @type {WeakMap<SerializeResult, function(): any | Promise<any>>} */\n\tconst resultToLazy = new WeakMap();\n\t/** @type {Buffer[]} */\n\tlet lastBuffers = undefined;\n\tfor (const item of await data) {\n\t\tif (typeof item === \"function\") {\n\t\t\tif (!SerializerMiddleware.isLazy(item))\n\t\t\t\tthrow new Error(\"Unexpected function\");\n\t\t\tif (!SerializerMiddleware.isLazy(item, middleware)) {\n\t\t\t\tthrow new Error(\n\t\t\t\t\t\"Unexpected lazy value with non-this target (can't pass through lazy values)\"\n\t\t\t\t);\n\t\t\t}\n\t\t\tlastBuffers = undefined;\n\t\t\tconst serializedInfo = SerializerMiddleware.getLazySerializedValue(item);\n\t\t\tif (serializedInfo) {\n\t\t\t\tif (typeof serializedInfo === \"function\") {\n\t\t\t\t\tthrow new Error(\n\t\t\t\t\t\t\"Unexpected lazy value with non-this target (can't pass through lazy values)\"\n\t\t\t\t\t);\n\t\t\t\t} else {\n\t\t\t\t\tprocessedData.push(serializedInfo);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst content = item();\n\t\t\t\tif (content) {\n\t\t\t\t\tconst options = SerializerMiddleware.getLazyOptions(item);\n\t\t\t\t\tprocessedData.push(\n\t\t\t\t\t\tserialize(\n\t\t\t\t\t\t\tmiddleware,\n\t\t\t\t\t\t\tcontent,\n\t\t\t\t\t\t\t(options && options.name) || true,\n\t\t\t\t\t\t\twriteFile,\n\t\t\t\t\t\t\thashFunction\n\t\t\t\t\t\t).then(result => {\n\t\t\t\t\t\t\t/** @type {any} */ (item).options.size = result.size;\n\t\t\t\t\t\t\tresultToLazy.set(result, item);\n\t\t\t\t\t\t\treturn result;\n\t\t\t\t\t\t})\n\t\t\t\t\t);\n\t\t\t\t} else {\n\t\t\t\t\tthrow new Error(\n\t\t\t\t\t\t\"Unexpected falsy value returned by lazy value function\"\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (item) {\n\t\t\tif (lastBuffers) {\n\t\t\t\tlastBuffers.push(item);\n\t\t\t} else {\n\t\t\t\tlastBuffers = [item];\n\t\t\t\tprocessedData.push(lastBuffers);\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new Error(\"Unexpected falsy value in items array\");\n\t\t}\n\t}\n\t/** @type {Promise<any>[]} */\n\tconst backgroundJobs = [];\n\tconst resolvedData = (\n\t\tawait Promise.all(\n\t\t\t/** @type {Promise<Buffer[] | Buffer | SerializeResult>[]} */ (\n\t\t\t\tprocessedData\n\t\t\t)\n\t\t)\n\t).map(item => {\n\t\tif (Array.isArray(item) || Buffer.isBuffer(item)) return item;\n\n\t\tbackgroundJobs.push(item.backgroundJob);\n\t\t// create pointer buffer from size and name\n\t\tconst name = /** @type {string} */ (item.name);\n\t\tconst nameBuffer = Buffer.from(name);\n\t\tconst buf = Buffer.allocUnsafe(8 + nameBuffer.length);\n\t\twriteUInt64LE(buf, item.size, 0);\n\t\tnameBuffer.copy(buf, 8, 0);\n\t\tconst lazy = resultToLazy.get(item);\n\t\tSerializerMiddleware.setLazySerializedValue(lazy, buf);\n\t\treturn buf;\n\t});\n\tconst lengths = [];\n\tfor (const item of resolvedData) {\n\t\tif (Array.isArray(item)) {\n\t\t\tlet l = 0;\n\t\t\tfor (const b of item) l += b.length;\n\t\t\twhile (l > 0x7fffffff) {\n\t\t\t\tlengths.push(0x7fffffff);\n\t\t\t\tl -= 0x7fffffff;\n\t\t\t}\n\t\t\tlengths.push(l);\n\t\t} else if (item) {\n\t\t\tlengths.push(-item.length);\n\t\t} else {\n\t\t\tthrow new Error(\"Unexpected falsy value in resolved data \" + item);\n\t\t}\n\t}\n\tconst header = Buffer.allocUnsafe(8 + lengths.length * 4);\n\theader.writeUInt32LE(VERSION, 0);\n\theader.writeUInt32LE(lengths.length, 4);\n\tfor (let i = 0; i < lengths.length; i++) {\n\t\theader.writeInt32LE(lengths[i], 8 + i * 4);\n\t}\n\tconst buf = [header];\n\tfor (const item of resolvedData) {\n\t\tif (Array.isArray(item)) {\n\t\t\tfor (const b of item) buf.push(b);\n\t\t} else if (item) {\n\t\t\tbuf.push(item);\n\t\t}\n\t}\n\tif (name === true) {\n\t\tname = hashForName(buf, hashFunction);\n\t}\n\tlet size = 0;\n\tfor (const b of buf) size += b.length;\n\tbackgroundJobs.push(writeFile(name, buf, size));\n\treturn {\n\t\tsize,\n\t\tname,\n\t\tbackgroundJob:\n\t\t\tbackgroundJobs.length === 1\n\t\t\t\t? backgroundJobs[0]\n\t\t\t\t: Promise.all(backgroundJobs)\n\t};\n};\n\n/**\n * @param {FileMiddleware} middleware this\n * @param {string | false} name filename\n * @param {function(string | false): Promise<Buffer[]>} readFile read content of a file\n * @returns {Promise<BufferSerializableType[]>} deserialized data\n */\nconst deserialize = async (middleware, name, readFile) => {\n\tconst contents = await readFile(name);\n\tif (contents.length === 0) throw new Error(\"Empty file \" + name);\n\tlet contentsIndex = 0;\n\tlet contentItem = contents[0];\n\tlet contentItemLength = contentItem.length;\n\tlet contentPosition = 0;\n\tif (contentItemLength === 0) throw new Error(\"Empty file \" + name);\n\tconst nextContent = () => {\n\t\tcontentsIndex++;\n\t\tcontentItem = contents[contentsIndex];\n\t\tcontentItemLength = contentItem.length;\n\t\tcontentPosition = 0;\n\t};\n\tconst ensureData = n => {\n\t\tif (contentPosition === contentItemLength) {\n\t\t\tnextContent();\n\t\t}\n\t\twhile (contentItemLength - contentPosition < n) {\n\t\t\tconst remaining = contentItem.slice(contentPosition);\n\t\t\tlet lengthFromNext = n - remaining.length;\n\t\t\tconst buffers = [remaining];\n\t\t\tfor (let i = contentsIndex + 1; i < contents.length; i++) {\n\t\t\t\tconst l = contents[i].length;\n\t\t\t\tif (l > lengthFromNext) {\n\t\t\t\t\tbuffers.push(contents[i].slice(0, lengthFromNext));\n\t\t\t\t\tcontents[i] = contents[i].slice(lengthFromNext);\n\t\t\t\t\tlengthFromNext = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tbuffers.push(contents[i]);\n\t\t\t\t\tcontentsIndex = i;\n\t\t\t\t\tlengthFromNext -= l;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (lengthFromNext > 0) throw new Error(\"Unexpected end of data\");\n\t\t\tcontentItem = Buffer.concat(buffers, n);\n\t\t\tcontentItemLength = n;\n\t\t\tcontentPosition = 0;\n\t\t}\n\t};\n\tconst readUInt32LE = () => {\n\t\tensureData(4);\n\t\tconst value = contentItem.readUInt32LE(contentPosition);\n\t\tcontentPosition += 4;\n\t\treturn value;\n\t};\n\tconst readInt32LE = () => {\n\t\tensureData(4);\n\t\tconst value = contentItem.readInt32LE(contentPosition);\n\t\tcontentPosition += 4;\n\t\treturn value;\n\t};\n\tconst readSlice = l => {\n\t\tensureData(l);\n\t\tif (contentPosition === 0 && contentItemLength === l) {\n\t\t\tconst result = contentItem;\n\t\t\tif (contentsIndex + 1 < contents.length) {\n\t\t\t\tnextContent();\n\t\t\t} else {\n\t\t\t\tcontentPosition = l;\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\tconst result = contentItem.slice(contentPosition, contentPosition + l);\n\t\tcontentPosition += l;\n\t\t// we clone the buffer here to allow the original content to be garbage collected\n\t\treturn l * 2 < contentItem.buffer.byteLength ? Buffer.from(result) : result;\n\t};\n\tconst version = readUInt32LE();\n\tif (version !== VERSION) {\n\t\tthrow new Error(\"Invalid file version\");\n\t}\n\tconst sectionCount = readUInt32LE();\n\tconst lengths = [];\n\tlet lastLengthPositive = false;\n\tfor (let i = 0; i < sectionCount; i++) {\n\t\tconst value = readInt32LE();\n\t\tconst valuePositive = value >= 0;\n\t\tif (lastLengthPositive && valuePositive) {\n\t\t\tlengths[lengths.length - 1] += value;\n\t\t} else {\n\t\t\tlengths.push(value);\n\t\t\tlastLengthPositive = valuePositive;\n\t\t}\n\t}\n\tconst result = [];\n\tfor (let length of lengths) {\n\t\tif (length < 0) {\n\t\t\tconst slice = readSlice(-length);\n\t\t\tconst size = Number(readUInt64LE(slice, 0));\n\t\t\tconst nameBuffer = slice.slice(8);\n\t\t\tconst name = nameBuffer.toString();\n\t\t\tresult.push(\n\t\t\t\tSerializerMiddleware.createLazy(\n\t\t\t\t\tmemoize(() => deserialize(middleware, name, readFile)),\n\t\t\t\t\tmiddleware,\n\t\t\t\t\t{\n\t\t\t\t\t\tname,\n\t\t\t\t\t\tsize\n\t\t\t\t\t},\n\t\t\t\t\tslice\n\t\t\t\t)\n\t\t\t);\n\t\t} else {\n\t\t\tif (contentPosition === contentItemLength) {\n\t\t\t\tnextContent();\n\t\t\t} else if (contentPosition !== 0) {\n\t\t\t\tif (length <= contentItemLength - contentPosition) {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(\n\t\t\t\t\t\t\tcontentItem.buffer,\n\t\t\t\t\t\t\tcontentItem.byteOffset + contentPosition,\n\t\t\t\t\t\t\tlength\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t} else {\n\t\t\t\t\tconst l = contentItemLength - contentPosition;\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(\n\t\t\t\t\t\t\tcontentItem.buffer,\n\t\t\t\t\t\t\tcontentItem.byteOffset + contentPosition,\n\t\t\t\t\t\t\tl\n\t\t\t\t\t\t)\n\t\t\t\t\t);\n\t\t\t\t\tlength -= l;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (length >= contentItemLength) {\n\t\t\t\t\tresult.push(contentItem);\n\t\t\t\t\tlength -= contentItemLength;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t} else {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(contentItem.buffer, contentItem.byteOffset, length)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (length > 0) {\n\t\t\t\tnextContent();\n\t\t\t\tif (length >= contentItemLength) {\n\t\t\t\t\tresult.push(contentItem);\n\t\t\t\t\tlength -= contentItemLength;\n\t\t\t\t\tcontentPosition = contentItemLength;\n\t\t\t\t} else {\n\t\t\t\t\tresult.push(\n\t\t\t\t\t\tBuffer.from(contentItem.buffer, contentItem.byteOffset, length)\n\t\t\t\t\t);\n\t\t\t\t\tcontentPosition += length;\n\t\t\t\t\tlength = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n};\n\n/**\n * @typedef {BufferSerializableType[]} DeserializedType\n * @typedef {true} SerializedType\n * @extends {SerializerMiddleware<DeserializedType, SerializedType>}\n */\nclass FileMiddleware extends SerializerMiddleware {\n\t/**\n\t * @param {IntermediateFileSystem} fs filesystem\n\t * @param {string | Hash} hashFunction hash function to use\n\t */\n\tconstructor(fs, hashFunction = \"md4\") {\n\t\tsuper();\n\t\tthis.fs = fs;\n\t\tthis._hashFunction = hashFunction;\n\t}\n\t/**\n\t * @param {DeserializedType} data data\n\t * @param {Object} context context object\n\t * @returns {SerializedType|Promise<SerializedType>} serialized data\n\t */\n\tserialize(data, context) {\n\t\tconst { filename, extension = \"\" } = context;\n\t\treturn new Promise((resolve, reject) => {\n\t\t\tmkdirp(this.fs, dirname(this.fs, filename), err => {\n\t\t\t\tif (err) return reject(err);\n\n\t\t\t\t// It's important that we don't touch existing files during serialization\n\t\t\t\t// because serialize may read existing files (when deserializing)\n\t\t\t\tconst allWrittenFiles = new Set();\n\t\t\t\tconst writeFile = async (name, content, size) => {\n\t\t\t\t\tconst file = name\n\t\t\t\t\t\t? join(this.fs, filename, `../${name}${extension}`)\n\t\t\t\t\t\t: filename;\n\t\t\t\t\tawait new Promise((resolve, reject) => {\n\t\t\t\t\t\tlet stream = this.fs.createWriteStream(file + \"_\");\n\t\t\t\t\t\tlet compression;\n\t\t\t\t\t\tif (file.endsWith(\".gz\")) {\n\t\t\t\t\t\t\tcompression = createGzip({\n\t\t\t\t\t\t\t\tchunkSize: COMPRESSION_CHUNK_SIZE,\n\t\t\t\t\t\t\t\tlevel: zConstants.Z_BEST_SPEED\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t} else if (file.endsWith(\".br\")) {\n\t\t\t\t\t\t\tcompression = createBrotliCompress({\n\t\t\t\t\t\t\t\tchunkSize: COMPRESSION_CHUNK_SIZE,\n\t\t\t\t\t\t\t\tparams: {\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_MODE]: zConstants.BROTLI_MODE_TEXT,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_QUALITY]: 2,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING]: true,\n\t\t\t\t\t\t\t\t\t[zConstants.BROTLI_PARAM_SIZE_HINT]: size\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (compression) {\n\t\t\t\t\t\t\tpipeline(compression, stream, reject);\n\t\t\t\t\t\t\tstream = compression;\n\t\t\t\t\t\t\tstream.on(\"finish\", () => resolve());\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstream.on(\"error\", err => reject(err));\n\t\t\t\t\t\t\tstream.on(\"finish\", () => resolve());\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// split into chunks for WRITE_LIMIT_CHUNK size\n\t\t\t\t\t\tconst chunks = [];\n\t\t\t\t\t\tfor (const b of content) {\n\t\t\t\t\t\t\tif (b.length < WRITE_LIMIT_CHUNK) {\n\t\t\t\t\t\t\t\tchunks.push(b);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tfor (let i = 0; i < b.length; i += WRITE_LIMIT_CHUNK) {\n\t\t\t\t\t\t\t\t\tchunks.push(b.slice(i, i + WRITE_LIMIT_CHUNK));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tconst len = chunks.length;\n\t\t\t\t\t\tlet i = 0;\n\t\t\t\t\t\tconst batchWrite = err => {\n\t\t\t\t\t\t\t// will be handled in \"on\" error handler\n\t\t\t\t\t\t\tif (err) return;\n\n\t\t\t\t\t\t\tif (i === len) {\n\t\t\t\t\t\t\t\tstream.end();\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// queue up a batch of chunks up to the write limit\n\t\t\t\t\t\t\t// end is exclusive\n\t\t\t\t\t\t\tlet end = i;\n\t\t\t\t\t\t\tlet sum = chunks[end++].length;\n\t\t\t\t\t\t\twhile (end < len) {\n\t\t\t\t\t\t\t\tsum += chunks[end].length;\n\t\t\t\t\t\t\t\tif (sum > WRITE_LIMIT_TOTAL) break;\n\t\t\t\t\t\t\t\tend++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\twhile (i < end - 1) {\n\t\t\t\t\t\t\t\tstream.write(chunks[i++]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tstream.write(chunks[i++], batchWrite);\n\t\t\t\t\t\t};\n\t\t\t\t\t\tbatchWrite();\n\t\t\t\t\t});\n\t\t\t\t\tif (name) allWrittenFiles.add(file);\n\t\t\t\t};\n\n\t\t\t\tresolve(\n\t\t\t\t\tserialize(this, data, false, writeFile, this._hashFunction).then(\n\t\t\t\t\t\tasync ({ backgroundJob }) => {\n\t\t\t\t\t\t\tawait backgroundJob;\n\n\t\t\t\t\t\t\t// Rename the index file to disallow access during inconsistent file state\n\t\t\t\t\t\t\tawait new Promise(resolve =>\n\t\t\t\t\t\t\t\tthis.fs.rename(filename, filename + \".old\", err => {\n\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t\t// update all written files\n\t\t\t\t\t\t\tawait Promise.all(\n\t\t\t\t\t\t\t\tArray.from(\n\t\t\t\t\t\t\t\t\tallWrittenFiles,\n\t\t\t\t\t\t\t\t\tfile =>\n\t\t\t\t\t\t\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\t\t\t\t\t\t\tthis.fs.rename(file + \"_\", file, err => {\n\t\t\t\t\t\t\t\t\t\t\t\tif (err) return reject(err);\n\t\t\t\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t\t// As final step automatically update the index file to have a consistent pack again\n\t\t\t\t\t\t\tawait new Promise(resolve => {\n\t\t\t\t\t\t\t\tthis.fs.rename(filename + \"_\", filename, err => {\n\t\t\t\t\t\t\t\t\tif (err) return reject(err);\n\t\t\t\t\t\t\t\t\tresolve();\n\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\treturn /** @type {true} */ (true);\n\t\t\t\t\t\t}\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * @param {SerializedType} data data\n\t * @param {Object} context context object\n\t * @returns {DeserializedType|Promise<DeserializedType>} deserialized data\n\t */\n\tdeserialize(data, context) {\n\t\tconst { filename, extension = \"\" } = context;\n\t\tconst readFile = name =>\n\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\tconst file = name\n\t\t\t\t\t? join(this.fs, filename, `../${name}${extension}`)\n\t\t\t\t\t: filename;\n\t\t\t\tthis.fs.stat(file, (err, stats) => {\n\t\t\t\t\tif (err) {\n\t\t\t\t\t\treject(err);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tlet remaining = /** @type {number} */ (stats.size);\n\t\t\t\t\tlet currentBuffer;\n\t\t\t\t\tlet currentBufferUsed;\n\t\t\t\t\tconst buf = [];\n\t\t\t\t\tlet decompression;\n\t\t\t\t\tif (file.endsWith(\".gz\")) {\n\t\t\t\t\t\tdecompression = createGunzip({\n\t\t\t\t\t\t\tchunkSize: DECOMPRESSION_CHUNK_SIZE\n\t\t\t\t\t\t});\n\t\t\t\t\t} else if (file.endsWith(\".br\")) {\n\t\t\t\t\t\tdecompression = createBrotliDecompress({\n\t\t\t\t\t\t\tchunkSize: DECOMPRESSION_CHUNK_SIZE\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\tlet newResolve, newReject;\n\t\t\t\t\t\tresolve(\n\t\t\t\t\t\t\tPromise.all([\n\t\t\t\t\t\t\t\tnew Promise((rs, rj) => {\n\t\t\t\t\t\t\t\t\tnewResolve = rs;\n\t\t\t\t\t\t\t\t\tnewReject = rj;\n\t\t\t\t\t\t\t\t}),\n\t\t\t\t\t\t\t\tnew Promise((resolve, reject) => {\n\t\t\t\t\t\t\t\t\tdecompression.on(\"data\", chunk => buf.push(chunk));\n\t\t\t\t\t\t\t\t\tdecompression.on(\"end\", () => resolve());\n\t\t\t\t\t\t\t\t\tdecompression.on(\"error\", err => reject(err));\n\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t]).then(() => buf)\n\t\t\t\t\t\t);\n\t\t\t\t\t\tresolve = newResolve;\n\t\t\t\t\t\treject = newReject;\n\t\t\t\t\t}\n\t\t\t\t\tthis.fs.open(file, \"r\", (err, fd) => {\n\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tconst read = () => {\n\t\t\t\t\t\t\tif (currentBuffer === undefined) {\n\t\t\t\t\t\t\t\tcurrentBuffer = Buffer.allocUnsafeSlow(\n\t\t\t\t\t\t\t\t\tMath.min(\n\t\t\t\t\t\t\t\t\t\tconstants.MAX_LENGTH,\n\t\t\t\t\t\t\t\t\t\tremaining,\n\t\t\t\t\t\t\t\t\t\tdecompression ? DECOMPRESSION_CHUNK_SIZE : Infinity\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\tcurrentBufferUsed = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlet readBuffer = currentBuffer;\n\t\t\t\t\t\t\tlet readOffset = currentBufferUsed;\n\t\t\t\t\t\t\tlet readLength = currentBuffer.length - currentBufferUsed;\n\t\t\t\t\t\t\t// values passed to fs.read must be valid int32 values\n\t\t\t\t\t\t\tif (readOffset > 0x7fffffff) {\n\t\t\t\t\t\t\t\treadBuffer = currentBuffer.slice(readOffset);\n\t\t\t\t\t\t\t\treadOffset = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (readLength > 0x7fffffff) {\n\t\t\t\t\t\t\t\treadLength = 0x7fffffff;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthis.fs.read(\n\t\t\t\t\t\t\t\tfd,\n\t\t\t\t\t\t\t\treadBuffer,\n\t\t\t\t\t\t\t\treadOffset,\n\t\t\t\t\t\t\t\treadLength,\n\t\t\t\t\t\t\t\tnull,\n\t\t\t\t\t\t\t\t(err, bytesRead) => {\n\t\t\t\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\t\t\t\tthis.fs.close(fd, () => {\n\t\t\t\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tcurrentBufferUsed += bytesRead;\n\t\t\t\t\t\t\t\t\tremaining -= bytesRead;\n\t\t\t\t\t\t\t\t\tif (currentBufferUsed === currentBuffer.length) {\n\t\t\t\t\t\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\t\t\t\t\t\tdecompression.write(currentBuffer);\n\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\tbuf.push(currentBuffer);\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tcurrentBuffer = undefined;\n\t\t\t\t\t\t\t\t\t\tif (remaining === 0) {\n\t\t\t\t\t\t\t\t\t\t\tif (decompression) {\n\t\t\t\t\t\t\t\t\t\t\t\tdecompression.end();\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\tthis.fs.close(fd, err => {\n\t\t\t\t\t\t\t\t\t\t\t\tif (err) {\n\t\t\t\t\t\t\t\t\t\t\t\t\treject(err);\n\t\t\t\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\tresolve(buf);\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tread();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t};\n\t\t\t\t\t\tread();\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t});\n\t\treturn deserialize(this, false, readFile);\n\t}\n}\n\nmodule.exports = FileMiddleware;\n"]},"metadata":{},"sourceType":"script"}